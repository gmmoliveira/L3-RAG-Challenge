{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "483c7611",
   "metadata": {},
   "source": [
    "# Implementação de Retrieval-Augmented Generation (RAG)\n",
    "\n",
    "### Autor: ***Guilherme Oliveira***\n",
    "### Contato: gmmoliveira1@gmail.com\n",
    "### Data: 16 de agosto de 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7ce2c4",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b621335d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agno.agent import Agent\n",
    "from agno.document.chunking.agentic import AgenticChunking\n",
    "from agno.embedder.ollama import OllamaEmbedder\n",
    "from agno.knowledge.pdf import PDFKnowledgeBase, PDFReader\n",
    "from agno.models.ollama import Ollama\n",
    "from agno.vectordb.pgvector import PgVector, SearchType\n",
    "from ollama import AsyncClient\n",
    "import yaml\n",
    "import asyncio\n",
    "from textwrap import dedent\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256bf809",
   "metadata": {},
   "source": [
    "#### Definição de Constantes\n",
    "\n",
    "Define constantes que controlam o funcionamento geral do script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4be9d5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "KNOWLEDGE_BASE_PATH = \"recursos/base_de_conhecimentos_PDFs/\"\n",
    "BASE_MODEL = \"qwen3:32b\"\n",
    "DATABASE_CONFIG_PATH = \"recursos/configs/database.yaml\"\n",
    "REQUIREMENTS_PATH = \"recursos/requirements.txt\"\n",
    "OLLAMA_HOST = \"http://localhost:54256\"\n",
    "QUESTIONS_PATH = \"recursos/sample_questions.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1cae6a7",
   "metadata": {},
   "source": [
    "Lê o arquivo de configurações e define a constante que determina como se conectar ao banco de dados vetorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d0e81a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DATABASE_CONFIG_PATH, 'r') as file:\n",
    "    database_config_aux = yaml.safe_load(file)\n",
    "database_config = database_config_aux[\"database\"]\n",
    "\n",
    "# postgresql+psycopg://<username>:<password>@<host>:<port>/<database>\n",
    "DATABASE_URL = f\"postgresql+psycopg://{database_config['user']}:{database_config['password']}@{database_config['host']}:{database_config['port']}/{database_config['dbname']}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588c9c03",
   "metadata": {},
   "source": [
    "#### Consolidação dos Requisitos Python\n",
    "\n",
    "Gera o arquivo `requirements.txt` para permitir reproduzir os resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9866dad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip freeze > $REQUIREMENTS_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded8c224",
   "metadata": {},
   "source": [
    "#### Download do LLM desejado\n",
    "\n",
    "Faz download do LLM escolhido utilizando o ollama."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d39ae4d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠧ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠇ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest \u001b[K\n",
      "pulling 3291abe70f16: 100% ▕██████████████████▏  20 GB                         \u001b[K\n",
      "pulling ae370d884f10: 100% ▕██████████████████▏ 1.7 KB                         \u001b[K\n",
      "pulling d18a5cc71b84: 100% ▕██████████████████▏  11 KB                         \u001b[K\n",
      "pulling cff3f395ef37: 100% ▕██████████████████▏  120 B                         \u001b[K\n",
      "pulling afdf5c7585b3: 100% ▕██████████████████▏  488 B                         \u001b[K\n",
      "verifying sha256 digest \u001b[K\n",
      "writing manifest \u001b[K\n",
      "success \u001b[K\u001b[?25h\u001b[?2026l\n"
     ]
    }
   ],
   "source": [
    "!ollama pull $BASE_MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2503032",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">INFO</span> Dropping collection                                                                                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mINFO\u001b[0m Dropping collection                                                                                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">INFO</span> Table <span style=\"color: #008000; text-decoration-color: #008000\">'ai.pdf_documents'</span> does not exist.                                                                      \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mINFO\u001b[0m Table \u001b[32m'ai.pdf_documents'\u001b[0m does not exist.                                                                      \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">INFO</span> Creating collection                                                                                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mINFO\u001b[0m Creating collection                                                                                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">INFO</span> Loading knowledge base                                                                                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mINFO\u001b[0m Loading knowledge base                                                                                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">INFO</span> Reading: Which Economic Tasks are Performed with AI_ Evidence from Millions of Claude Conversations           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mINFO\u001b[0m Reading: Which Economic Tasks are Performed with AI_ Evidence from Millions of Claude Conversations           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">INFO</span> Upserted batch of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18</span> documents.                                                                               \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mINFO\u001b[0m Upserted batch of \u001b[1;36m18\u001b[0m documents.                                                                               \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">INFO</span> Added <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18</span> documents to knowledge base                                                                          \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mINFO\u001b[0m Added \u001b[1;36m18\u001b[0m documents to knowledge base                                                                          \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cria a instância a classe que transforma texto em embeddings\n",
    "embedder = OllamaEmbedder(\n",
    "    dimensions=5120, # ajustar em acordo com o LLM escolhido\n",
    "    id=BASE_MODEL,\n",
    ")\n",
    "# cria a base de dados do PostgreSQL empoderada com busca vetorial\n",
    "database = PgVector(\n",
    "    table_name=\"pdf_documents\",\n",
    "    db_url=DATABASE_URL,\n",
    "    search_type=SearchType.hybrid,\n",
    "    embedder=embedder,\n",
    ")\n",
    "# Cria a instância do leitor de PDFs para consumir o artigo \n",
    "reader = PDFReader(\n",
    "    split_on_pages=False,\n",
    "    chunk=True,\n",
    ")\n",
    "# Cria a instância que determina como dividir o arquivo PDF\n",
    "chunking_strategy = AgenticChunking(\n",
    "    model=BASE_MODEL,\n",
    "    max_chunk_size=5000,\n",
    ")\n",
    "# Cria a instância da base de conhecimento\n",
    "pdf_knowledge_base = PDFKnowledgeBase(\n",
    "    path=KNOWLEDGE_BASE_PATH,\n",
    "    vector_db=database,\n",
    "    reader=reader,\n",
    "    chunking_strategy=chunking_strategy,\n",
    "    num_documents=15,\n",
    ")\n",
    "# Carrega os dados do PDF no banco de dados\n",
    "pdf_knowledge_base.load(\n",
    "    recreate=True,\n",
    "    upsert=True,\n",
    "    skip_existing=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d4ba83",
   "metadata": {},
   "source": [
    "Foram criados 18 fragmentos para o artigo que será utilizado como base de conhecimento\n",
    "\n",
    "#### Instanciação do LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64157c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria uma forma de acessar o LLM via ollama de maneira assíncrona\n",
    "async_client = AsyncClient(\n",
    "    host=OLLAMA_HOST,\n",
    "    headers={\n",
    "        \"temperature\": \"0.15\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68ba8bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria uma instância do LLM que utiliza como base um único servidor\n",
    "model = Ollama(\n",
    "    id=BASE_MODEL,\n",
    "    async_client=async_client,\n",
    ")\n",
    "# Cria uma instância do agente que irá utilizar o LLM\n",
    "agent = Agent(\n",
    "    model=model,\n",
    "    knowledge=pdf_knowledge_base,\n",
    "    description=dedent(\"\"\"\n",
    "        You are a **Search-Based Research Agent**, an expert in retrieving and synthesizing the most current,\n",
    "        accurate information from trusted sources. Your core function is to answer user queries\n",
    "        exclusively using data obtained through real-time search tool calls. You must never rely\n",
    "        on pre-trained knowledge, assumptions, or unsourced information. Prioritize credibility,\n",
    "        recency, and relevance in all responses.\n",
    "    \"\"\"),\n",
    "    instructions=[\n",
    "        dedent(\"\"\"\n",
    "        1. **Mandatory Search Activation**:  \n",
    "            - For **every** user query, invoke the search tool immediately.  \n",
    "            - Generate 1–3 optimized search queries targeting credible sources (e.g., academic journals, official reports, reputable news).  \n",
    "            *Example: Querying \"peer-reviewed definition of quantum entanglement\" instead of \"what is quantum entanglement?\"* \n",
    "        \"\"\"),\n",
    "        dedent(\"\"\"\n",
    "        2. **Information Synthesis**:  \n",
    "            - Extract **only** facts from the top 3–5 search results. Cross-verify overlapping information across sources.  \n",
    "            - Discard conflicting/low-credibility data (e.g., unverified forums, outdated pages).  \n",
    "        \"\"\"),\n",
    "        dedent(\"\"\"\n",
    "        3. **Response Structure**:  \n",
    "            - **Attribution**: Cite sources for every claim. Format: `[Source: Domain/Title]`.  \n",
    "            - **Conciseness**: Answer directly in ≤3 sentences.  \n",
    "            - **Uncertainty Handling**: If sources are inadequate, respond:  \n",
    "                > \"I found no verified sources on this topic. Refine your query or ask another question.\"  \n",
    "        \"\"\"),\n",
    "        dedent(\"\"\"\n",
    "        4. **Prohibitions**:  \n",
    "            - No speculation, opinions, or unsupported statements.  \n",
    "            - No use of internal knowledge without search validation.  \n",
    "        \"\"\"),\n",
    "        dedent(\"\"\"\n",
    "        5. **Language**:\n",
    "            - Answer using the same language as the user is using in their queries. When necessary, keep technical terms in english (e.g., Retrieval-Augmented Generation---RAG).\n",
    "        \"\"\"),\n",
    "        dedent(\"\"\"\n",
    "        ### Example Interaction  \n",
    "            **User**: Define \"neuromorphic computing.\"  \n",
    "            **Agent**:  \n",
    "            1. *Searches*: [\"neuromorphic computing definition academic\"], [\"neuromorphic vs traditional architecture peer-reviewed\"].  \n",
    "            2. *Synthesizes*:  \n",
    "            > \"Neuromorphic computing designs hardware to mimic the brain’s neural structure for energy-efficient AI processing [Source: Nature Electronics]. It uses spiking neural networks for real-time learning [Source: IEEE Spectrum].\"  \n",
    "        \"\"\"),\n",
    "        dedent(\"\"\"\n",
    "        **Key Principles**:  \n",
    "            - **Search-First**: All answers originate from tool-retrieved data.  \n",
    "            - **Precision > Creativity**: Prioritize factual accuracy over engagement.  \n",
    "            - **Source Transparency**: Always expose origins for user verification.\n",
    "            - **User Language Matching**: Answer in the same language the user uses (e.g., Portuguese).\n",
    "        \"\"\"),\n",
    "    ],\n",
    "    search_knowledge=True,\n",
    "    show_tool_calls=True,\n",
    "    markdown=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b1a26a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Qual é o principal objetivo do estudo conduzido pela Anthropic?',\n",
       " 'Quais são as duas categorias de tarefas que concentram quase metade do uso de IA?',\n",
       " 'Que porcentagem de ocupações usa IA para pelo menos 25% de suas tarefas associadas?',\n",
       " 'Como os autores categorizam os padrões de uso entre automação e aumento (augmentation)?',\n",
       " 'Quais habilidades ocupacionais são mais prevalentes nas conversas com IA?',\n",
       " 'Como o uso de IA varia conforme o salário das ocupações?',\n",
       " 'Qual é a principal limitação dos dados utilizados no estudo?',\n",
       " 'Como os modelos Claude 3 Opus e Claude 3.5 Sonnet diferem nos padrões de uso?',\n",
       " 'Qual framework teórico fundamenta a análise das tarefas econômicas?',\n",
       " 'Que tipo de ocupações apresenta menor penetração de IA segundo o estudo?']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(QUESTIONS_PATH, 'r') as f:\n",
    "    questions = json.load(f)[\"questions\"]\n",
    "questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac9702f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36289fd07d314fe2b849b30a594a310a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">INFO</span> Found <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span> documents                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mINFO\u001b[0m Found \u001b[1;36m15\u001b[0m documents                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "680653f5c0414a0caeb71e4e52b8579f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">INFO</span> Found <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span> documents                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mINFO\u001b[0m Found \u001b[1;36m15\u001b[0m documents                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "219add8c9b0d425ab9b1344860940453",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">INFO</span> Found <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span> documents                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mINFO\u001b[0m Found \u001b[1;36m15\u001b[0m documents                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c25120f15da542f5957fd2f3021af29e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">INFO</span> Found <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span> documents                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mINFO\u001b[0m Found \u001b[1;36m15\u001b[0m documents                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83e58d7cfe824d0b8d01337b38d9208d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">INFO</span> Found <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span> documents                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mINFO\u001b[0m Found \u001b[1;36m15\u001b[0m documents                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87bd6e23fa77471bb36b9e5c5bb6c84d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">INFO</span> Found <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span> documents                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mINFO\u001b[0m Found \u001b[1;36m15\u001b[0m documents                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77c61789f54b4cef9e39ced508509af4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">INFO</span> Found <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span> documents                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mINFO\u001b[0m Found \u001b[1;36m15\u001b[0m documents                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">INFO</span> Found <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span> documents                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mINFO\u001b[0m Found \u001b[1;36m15\u001b[0m documents                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86112263ed964125a7ab36a0387757f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">INFO</span> Found <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span> documents                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mINFO\u001b[0m Found \u001b[1;36m15\u001b[0m documents                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1061b521dbf4d2180296d901e509152",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">INFO</span> Found <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span> documents                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mINFO\u001b[0m Found \u001b[1;36m15\u001b[0m documents                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bfd9620ed364e599e9f40e551fc3bb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">INFO</span> Found <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span> documents                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mINFO\u001b[0m Found \u001b[1;36m15\u001b[0m documents                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "for question in questions:\n",
    "    # Gera 1 resposta por vez e apresenta na tela via streamming\n",
    "    agent.print_response(question, stream=True, markdown=True)\n",
    "    # Permite gerar a resposta assíncrona, porém não favorece a visualização\n",
    "    #asyncio.run(agent.print_response(question, markdown=True))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
